{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:18:54.176375Z",
     "start_time": "2020-06-14T16:18:53.967362Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:18:58.081211Z",
     "start_time": "2020-06-14T16:18:54.193205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading postgres module without psycopg2 installed. Will crash at runtime if postgres functionality is used.\n",
      "Loading S3 module without the python package boto3. Will crash at runtime if S3 functionality is used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to d6tflow!\n",
      "C:\\Users\\mdetomaso\\Desktop\\K_Code\\custom-ml-pipelines\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Common imports\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pickle import dump, load\n",
    "import os\n",
    "\n",
    "# Databolt imports\n",
    "import d6tflow\n",
    "import luigi\n",
    "from luigi.util import inherits\n",
    "\n",
    "# Ignore useless warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "os.chdir((Path.cwd() / \"\").parents[0])\n",
    "base_path = os.getcwd()\n",
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:18:58.362136Z",
     "start_time": "2020-06-14T16:18:58.084902Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.config import read_config\n",
    "from src.input_collector import InputArguments, DataAccessor\n",
    "from src.databolt_pipeline_modeler import (\n",
    "    databolt_training_dataflow, \n",
    "    databolt_prediction_dataflow,\n",
    "    get_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:18:58.610529Z",
     "start_time": "2020-06-14T16:18:58.368268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configurations filepath: C:/Users/mdetomaso/Desktop/K_Code/custom-ml-pipelines/conf/config.json\n",
      "Reading Housing model configuration ........\n"
     ]
    }
   ],
   "source": [
    "# Identify the path to the configurations folder\n",
    "config_path = str(base_path.replace(\"\\\\\", \"/\") +\"/\"+\"conf\")\n",
    "args = InputArguments(pathConfFile=config_path)\n",
    "\n",
    "def prepare_config_path(args) -> dict:\n",
    "    config_path = f\"{args.pathConfFile}/{{}}\"\n",
    "    print(\"Training configurations filepath: {}\".format(config_path.format(\"config.json\")))\n",
    "    return {\"config\": config_path.format(\"config.json\")}\n",
    "\n",
    "    # Prepare paths to config file and eventual other files\n",
    "\n",
    "file_paths = prepare_config_path(args)\n",
    "\n",
    "# Read config\n",
    "print(\"Reading Housing model configuration ........\")\n",
    "config_path = file_paths[\"config\"]\n",
    "cfg = read_config(config_path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:18:58.845572Z",
     "start_time": "2020-06-14T16:18:58.614853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/processed')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Databolt related settings\n",
    "d6tflow.settings.log_level = 'ERROR' # 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'\n",
    "# set the repo for eack task output\n",
    "d6tflow.set_dir(dir='data/processed') \n",
    "# folder where workflow outputs are saved\n",
    "d6tflow.settings.dirpath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:18:59.731491Z",
     "start_time": "2020-06-14T16:18:58.851663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access housing data\n",
    "housing = DataAccessor(**cfg.input_config).load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:20:48.744386Z",
     "start_time": "2020-06-14T16:18:59.734280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute Training pipeline.\n",
      "Housing data loaded successfully.\n",
      "Stratified Train / Test split.\n",
      "Train set dimesions: (16512, 11)\n",
      "Test set dimesions: (4128, 11)\n",
      "Train target dimesions: (16512,)\n",
      "Test target dimesions: (4128,)\n",
      "Numerical missing values imputed.\n",
      "New numerical attributes created.\n",
      "Numerical missing values imputed.\n",
      "New numerical attributes created.\n",
      "Categorical missing values imputed.\n",
      "Categorical data encoded.\n",
      "All features processed.\n",
      "Doing model training and prediction.\n",
      "Model scored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Execute Training pipeline.\")\n",
    "\n",
    "databolt_training_dataflow(\n",
    "    config=cfg, input_kwargs=cfg.input_config, training_kwargs=cfg.training_config,\n",
    "    testing_kwargs=cfg.testing_config, do_split=True, train=True, \n",
    "    estimator=RandomForestRegressor(), evaluation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:20:52.787480Z",
     "start_time": "2020-06-14T16:20:52.048184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute Prediction pipeline on test data.\n",
      "Model scored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = get_model_path(config=cfg, estimator=RandomForestRegressor(), input_kwargs=cfg.input_config,\n",
    "                            training_kwargs=cfg.training_config, testing_kwargs=cfg.testing_config)\n",
    "\n",
    "print(\"Execute Prediction pipeline on test data.\")\n",
    "\n",
    "databolt_prediction_dataflow(\n",
    "    config=cfg, input_kwargs=cfg.input_config, training_kwargs=cfg.training_config,\n",
    "    testing_kwargs=cfg.testing_config, do_split=True, test=True, \n",
    "    model_path=model_path, evaluation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T16:20:59.061720Z",
     "start_time": "2020-06-14T16:20:52.795168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute Prediction pipeline on housing data.\n",
      "Categorical missing values imputed.\n",
      "Categorical data encoded.\n",
      "All features processed.\n",
      "Using trained model and doing predictions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = get_model_path(config=cfg, estimator=RandomForestRegressor(), input_kwargs=cfg.input_config,\n",
    "                            training_kwargs=cfg.training_config, testing_kwargs=cfg.testing_config)\n",
    "\n",
    "print(\"Execute Prediction pipeline on housing data.\")\n",
    "\n",
    "databolt_prediction_dataflow(\n",
    "    config=cfg, input_kwargs=cfg.input_config, training_kwargs=cfg.training_config,\n",
    "    testing_kwargs=cfg.testing_config, do_split=False, \n",
    "    model_path=model_path, evaluation=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:demo] *",
   "language": "python",
   "name": "conda-env-demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
