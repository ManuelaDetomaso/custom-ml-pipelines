{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:22:47.709479Z",
     "start_time": "2020-06-12T18:22:47.646720Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:22:48.207302Z",
     "start_time": "2020-06-12T18:22:47.709479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python â‰¥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Common imports\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Ignore useless warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:22:48.270855Z",
     "start_time": "2020-06-12T18:22:48.207302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the repo root directory to use as base path\n",
    "os.chdir((Path.cwd() / \"\").parents[0]) # to change with base path\n",
    "base_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:22:48.934939Z",
     "start_time": "2020-06-12T18:22:48.270855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import project specific libraries\n",
    "from src.config import read_config\n",
    "from src.custom_pipeline_modeler import custom_dataflow\n",
    "from src.input_collector import InputArguments, DataAccessor\n",
    "from src.sk_pipeline_modeler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:22:49.035153Z",
     "start_time": "2020-06-12T18:22:48.934939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configurations filepath: C:/Users/mdetomaso/Desktop/K_Code/custom-ml-pipelines/conf/config.json\n",
      "Reading Housing model configuration ........\n"
     ]
    }
   ],
   "source": [
    "# identify the path to the configurations folder\n",
    "config_path = str(base_path.replace(\"\\\\\", \"/\") +\"/\"+\"conf\")\n",
    "args = InputArguments(pathConfFile=config_path)\n",
    "\n",
    "def prepare_config_path(args) -> dict:\n",
    "    config_path = f\"{args.pathConfFile}/{{}}\"\n",
    "    print(\"Training configurations filepath: {}\".format(config_path.format(\"config.json\")))\n",
    "    return {\"config\": config_path.format(\"config.json\")}\n",
    "\n",
    "    # Prepare paths to config file and eventual other files\n",
    "\n",
    "file_paths = prepare_config_path(args)\n",
    "\n",
    "# Read config\n",
    "print(\"Reading Housing model configuration ........\")\n",
    "config_path = file_paths[\"config\"]\n",
    "cfg = read_config(config_path=config_path)\n",
    "\n",
    "#Select path to data to process\n",
    "train_data_path = cfg.trainset_path\n",
    "test_data_path = cfg.testset_path\n",
    "train_target_path = cfg.train_target_path\n",
    "test_target_path = cfg.test_target_path\n",
    "prod_data_path = cfg.housing_data_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:22:49.392271Z",
     "start_time": "2020-06-12T18:22:49.035153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access housing data\n",
    "housing = DataAccessor(**cfg.input_config).load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:23:37.267857Z",
     "start_time": "2020-06-12T18:22:51.326490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Housing model training dataflow ........\n",
      "collect-data-stage ........\n",
      "Housing data loaded successfully.\n",
      "split-train-test-stage ........\n",
      "Read data/input/housing.csv\n",
      "Stratified Train / Test split.\n",
      "Train set dimesions: (16512, 11)\n",
      "Test set dimesions: (4128, 11)\n",
      "Train target dimesions: (16512,)\n",
      "Test target dimesions: (4128,)\n",
      "data/outputs/partitions/train_set.csv\n",
      "Wrote data/outputs/partitions/train_set.csv\n",
      "data/outputs/partitions/train_target.csv\n",
      "Wrote data/outputs/partitions/train_target.csv\n",
      "data/outputs/partitions/test_set.csv\n",
      "Wrote data/outputs/partitions/test_set.csv\n",
      "data/outputs/partitions/test_target.csv\n",
      "Wrote data/outputs/partitions/test_target.csv\n",
      "data/outputs/partitions/train_test_sets.csv\n",
      "Wrote data/outputs/partitions/train_test_sets.csv\n",
      "select-numerical-attributes-stage ........\n",
      "Read data/outputs/partitions/train_set.csv\n",
      "Wrote data/outputs/numerical_features.csv\n",
      "impute-numerical-missing-values-stage ........\n",
      "Read data/outputs/numerical_features.csv\n",
      "Numerical missing values imputed.\n",
      "Wrote data/outputs/imputed_numerical_features.csv\n",
      "create-new-attributes-stage ........\n",
      "Read data/outputs/imputed_numerical_features.csv\n",
      "New numerical attributes created.\n",
      "Wrote data/outputs/enriched_numerical_features.csv\n",
      "scale-numerical-attributes-stage ........\n",
      "Read data/outputs/enriched_numerical_features.csv\n",
      "Wrote data/outputs/model_artifacts/numerical_scaler.pkl\n",
      "Wrote data/outputs/scaled_numerical_features.csv\n",
      "select-categorical-attributes-stage ........\n",
      "Read data/outputs/partitions/train_set.csv\n",
      "Wrote data/outputs/categorical_features.csv\n",
      "impute-categorical-missing-values-stage ........\n",
      "Read data/outputs/categorical_features.csv\n",
      "Categorical missing values imputed.\n",
      "Wrote data/outputs/imputed_categorical_features.csv\n",
      "encode-categorical-features-stage ........\n",
      "Read data/outputs/imputed_categorical_features.csv\n",
      "Categorical data encoded.\n",
      "Wrote data/outputs/encoded_categorical_features.csv\n",
      "merge-num-cat-features-stage ........\n",
      "Read data/outputs/scaled_numerical_features.csv\n",
      "Read data/outputs/encoded_categorical_features.csv\n",
      "Wrote data/outputs/all_processed.csv\n",
      "train-model-stage ........\n",
      "Read data/outputs/all_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdetomaso\\Anaconda3\\envs\\demo\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data/outputs/model_artifacts/trained_housing_model.pkl\n",
      "make-predictions-stage ........\n",
      "Load model from data/outputs/model_artifacts/trained_housing_model.pkl\n",
      "Read data/outputs/all_processed.csv\n",
      "Wrote data/outputs/predictions.csv\n",
      "evaluate-results-stage ........\n",
      "Read data/outputs/predictions.csv\n",
      "Read data/outputs/partitions/train_target.csv\n",
      "Read data/outputs/predictions.csv\n",
      "Read data/outputs/partitions/train_target.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    17938.528303\n",
       "Name: RMSE, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_training_pipeline(\n",
    "    args, config=cfg, data_path=train_data_path, target_path=train_target_path, env=None\n",
    "):\n",
    "    custom_pipeline = custom_dataflow(\n",
    "        args=args, config=config, data_path=data_path, target_path=target_path, env=env\n",
    "    )\n",
    "    estimator = RandomForestRegressor()\n",
    "    stages = [\n",
    "        \"collect-data-stage\",\n",
    "        \"split-train-test-stage\",\n",
    "        \"select-numerical-attributes-stage\",\n",
    "        \"impute-numerical-missing-values-stage\",\n",
    "        \"create-new-attributes-stage\",\n",
    "        \"scale-numerical-attributes-stage\",\n",
    "        \"select-categorical-attributes-stage\",\n",
    "        \"impute-categorical-missing-values-stage\",\n",
    "        \"encode-categorical-features-stage\",\n",
    "        \"merge-num-cat-features-stage\",\n",
    "        \"train-model-stage\", #step needed only for training\n",
    "        \"make-predictions-stage\",\n",
    "        \"evaluate-results-stage\" #step used only when target is avialable\n",
    "             ]\n",
    "\n",
    "    for stage in stages:\n",
    "        stage = custom_pipeline.stages[stage]\n",
    "        print(stage.name, \"........\")\n",
    "        stage.run()\n",
    "    return custom_pipeline\n",
    "\n",
    "training_pipe = custom_training_pipeline(args, env=None)\n",
    "# Look at results\n",
    "stage = training_pipe.stages[\"evaluate-results-stage\"]\n",
    "stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:23:38.294644Z",
     "start_time": "2020-06-12T18:23:37.269832Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Housing model training dataflow ........\n",
      "select-numerical-attributes-stage ........\n",
      "Read data/outputs/partitions/test_set.csv\n",
      "Wrote data/outputs/numerical_features.csv\n",
      "impute-numerical-missing-values-stage ........\n",
      "Read data/outputs/numerical_features.csv\n",
      "Numerical missing values imputed.\n",
      "Wrote data/outputs/imputed_numerical_features.csv\n",
      "create-new-attributes-stage ........\n",
      "Read data/outputs/imputed_numerical_features.csv\n",
      "New numerical attributes created.\n",
      "Wrote data/outputs/enriched_numerical_features.csv\n",
      "scale-numerical-attributes-stage ........\n",
      "Read data/outputs/enriched_numerical_features.csv\n",
      "Wrote data/outputs/model_artifacts/numerical_scaler.pkl\n",
      "Wrote data/outputs/scaled_numerical_features.csv\n",
      "select-categorical-attributes-stage ........\n",
      "Read data/outputs/partitions/test_set.csv\n",
      "Wrote data/outputs/categorical_features.csv\n",
      "impute-categorical-missing-values-stage ........\n",
      "Read data/outputs/categorical_features.csv\n",
      "Categorical missing values imputed.\n",
      "Wrote data/outputs/imputed_categorical_features.csv\n",
      "encode-categorical-features-stage ........\n",
      "Read data/outputs/imputed_categorical_features.csv\n",
      "Categorical data encoded.\n",
      "Wrote data/outputs/encoded_categorical_features.csv\n",
      "merge-num-cat-features-stage ........\n",
      "Read data/outputs/scaled_numerical_features.csv\n",
      "Read data/outputs/encoded_categorical_features.csv\n",
      "Wrote data/outputs/all_processed.csv\n",
      "make-predictions-stage ........\n",
      "Load model from data/outputs/model_artifacts/trained_housing_model.pkl\n",
      "Read data/outputs/all_processed.csv\n",
      "Wrote data/outputs/predictions.csv\n",
      "evaluate-results-stage ........\n",
      "Read data/outputs/predictions.csv\n",
      "Read data/outputs/partitions/test_target.csv\n",
      "Read data/outputs/predictions.csv\n",
      "Read data/outputs/partitions/test_target.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    53094.055981\n",
       "Name: RMSE, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_testing_pipeline(\n",
    "    args, config=cfg, data_path=test_data_path, target_path=test_target_path, env=None\n",
    "):\n",
    "    custom_pipeline = custom_dataflow(\n",
    "        args=args, config=config, data_path=data_path, target_path=target_path, env=env\n",
    "    )\n",
    "    estimator = RandomForestRegressor()\n",
    "    stages = [\n",
    "        \"select-numerical-attributes-stage\",\n",
    "        \"impute-numerical-missing-values-stage\",\n",
    "        \"create-new-attributes-stage\",\n",
    "        \"scale-numerical-attributes-stage\",\n",
    "        \"select-categorical-attributes-stage\",\n",
    "        \"impute-categorical-missing-values-stage\",\n",
    "        \"encode-categorical-features-stage\",\n",
    "        \"merge-num-cat-features-stage\",\n",
    "        \"make-predictions-stage\",\n",
    "        \"evaluate-results-stage\"\n",
    "             ]\n",
    "\n",
    "    for stage in stages:\n",
    "        stage = custom_pipeline.stages[stage]\n",
    "        print(stage.name, \"........\")\n",
    "        stage.run()\n",
    "    return custom_pipeline\n",
    "\n",
    "testing_pipe = custom_testing_pipeline(args, env=None)\n",
    "# Look at results\n",
    "stage = testing_pipe.stages[\"evaluate-results-stage\"]\n",
    "stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:23:40.894333Z",
     "start_time": "2020-06-12T18:23:38.294644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Housing model training dataflow ........\n",
      "select-numerical-attributes-stage ........\n",
      "Read data/input/housing.csv\n",
      "Wrote data/outputs/numerical_features.csv\n",
      "impute-numerical-missing-values-stage ........\n",
      "Read data/outputs/numerical_features.csv\n",
      "Numerical missing values imputed.\n",
      "Wrote data/outputs/imputed_numerical_features.csv\n",
      "create-new-attributes-stage ........\n",
      "Read data/outputs/imputed_numerical_features.csv\n",
      "New numerical attributes created.\n",
      "Wrote data/outputs/enriched_numerical_features.csv\n",
      "scale-numerical-attributes-stage ........\n",
      "Read data/outputs/enriched_numerical_features.csv\n",
      "Wrote data/outputs/model_artifacts/numerical_scaler.pkl\n",
      "Wrote data/outputs/scaled_numerical_features.csv\n",
      "select-categorical-attributes-stage ........\n",
      "Read data/input/housing.csv\n",
      "Wrote data/outputs/categorical_features.csv\n",
      "impute-categorical-missing-values-stage ........\n",
      "Read data/outputs/categorical_features.csv\n",
      "Categorical missing values imputed.\n",
      "Wrote data/outputs/imputed_categorical_features.csv\n",
      "encode-categorical-features-stage ........\n",
      "Read data/outputs/imputed_categorical_features.csv\n",
      "Categorical data encoded.\n",
      "Wrote data/outputs/encoded_categorical_features.csv\n",
      "merge-num-cat-features-stage ........\n",
      "Read data/outputs/scaled_numerical_features.csv\n",
      "Read data/outputs/encoded_categorical_features.csv\n",
      "Wrote data/outputs/all_processed.csv\n",
      "make-predictions-stage ........\n",
      "Load model from data/outputs/model_artifacts/trained_housing_model.pkl\n",
      "Read data/outputs/all_processed.csv\n",
      "Wrote data/outputs/predictions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423636.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391698.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>399827.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330156.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>281872.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>79162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>80454.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>87975.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>83307.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>87626.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictions\n",
       "0        423636.11\n",
       "1        391698.07\n",
       "2        399827.09\n",
       "3        330156.03\n",
       "4        281872.00\n",
       "...            ...\n",
       "20635     79162.00\n",
       "20636     80454.00\n",
       "20637     87975.00\n",
       "20638     83307.99\n",
       "20639     87626.99\n",
       "\n",
       "[20640 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_prod_pipeline(\n",
    "    args, config=cfg, data_path=prod_data_path, target_path=None, env=None\n",
    "):\n",
    "    custom_pipeline = custom_dataflow(\n",
    "        args=args, config=config, data_path=data_path, target_path=target_path, env=env\n",
    "    )\n",
    "    estimator = RandomForestRegressor()\n",
    "    stages = [\n",
    "        \"select-numerical-attributes-stage\",\n",
    "        \"impute-numerical-missing-values-stage\",\n",
    "        \"create-new-attributes-stage\",\n",
    "        \"scale-numerical-attributes-stage\",\n",
    "        \"select-categorical-attributes-stage\",\n",
    "        \"impute-categorical-missing-values-stage\",\n",
    "        \"encode-categorical-features-stage\",\n",
    "        \"merge-num-cat-features-stage\",\n",
    "        \"make-predictions-stage\"\n",
    "             ]\n",
    "\n",
    "    for stage in stages:\n",
    "        stage = custom_pipeline.stages[stage]\n",
    "        print(stage.name, \"........\")\n",
    "        stage.run()\n",
    "    return custom_pipeline\n",
    "\n",
    "prod_pipe = custom_prod_pipeline(args, env=None)\n",
    "predictions = pd.read_csv(\"data/outputs/predictions.csv\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, a shorter pipeline with less steps could have included...\n",
    "\n",
    "- stage_1. CollectDataStage\n",
    "\n",
    "- stage_2. PartitionDataStage\n",
    "\n",
    "- stage_3. ProcessNumericalFeaturesStage (all numerical features related preprocessing steps)\n",
    "\n",
    "- stage_4. ProcessCategoricalFeaturesStage (all numerical features related preprocessing steps)\n",
    "\n",
    "- stage_5. TrainModelStage\n",
    "\n",
    "- stage_6. PredictStage\n",
    "\n",
    "- stage_7. EvaluateStage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:demo] *",
   "language": "python",
   "name": "conda-env-demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
